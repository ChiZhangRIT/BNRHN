{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC:\n",
    "* [Genarete captions for test data](#genarete_captions_for_test_data)\n",
    "* [Evaluation](#evaluation)\n",
    "\n",
    "These two sections implement the same as get_scores.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "from inference_utils import caption_generator\n",
    "from inference_utils import vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genarete captions for test data <a id=\"genarete_captions_for_test_data\"></a>\n",
    "\n",
    "Please run generate_captions.py, instead of using this section in jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cis/phd/cxz2081/data/mscoco/captioning/val2014/COCO_val2014_000000126229.jpg', '/cis/phd/cxz2081/data/mscoco/captioning/val2014/COCO_val2014_000000579325.jpg', '/cis/phd/cxz2081/data/mscoco/captioning/val2014/COCO_val2014_000000499989.jpg', '/cis/phd/cxz2081/data/mscoco/captioning/val2014/COCO_val2014_000000065024.jpg', '/cis/phd/cxz2081/data/mscoco/captioning/val2014/COCO_val2014_000000575897.jpg']\n"
     ]
    }
   ],
   "source": [
    "file_name_list = os.listdir(\"/cis/phd/cxz2081/data/mscoco/captioning/val2014\")\n",
    "file_name_list = ['/cis/phd/cxz2081/data/mscoco/captioning/val2014/' + i for i in file_name_list]\n",
    "file_name_list = file_name_list[:5]  # DEBUG\n",
    "print(file_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "tf.flags.DEFINE_string(\"checkpoint_path\", \"model/train\", \"Model checkpoint file or directory containing a model checkpoint file.\")\n",
    "tf.flags.DEFINE_string(\"vocab_file\", \"data/mscoco/word_counts.txt\", \"Text file containing the vocabulary.\")\n",
    "tf.flags.DEFINE_string(\"input_files\", file_name_list, \"File pattern or comma-separated list of file patterns of image files.\")\n",
    "tf.flags.DEFINE_string(\"captions_file\", \"/cis/phd/cxz2081/data/mscoco/captioning/annotations/captions_val2014.json\", \"JSON file containing caption annotations..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the filenames and ids.\n",
    "with tf.gfile.FastGFile(FLAGS.captions_file, \"r\") as f:\n",
    "    caption_data = json.load(f)\n",
    "\n",
    "filename_to_id = {\"/cis/phd/cxz2081/data/mscoco/captioning/val2014/\" + x[\"file_name\"]: x[\"id\"] for x in caption_data[\"images\"]}\n",
    "id_to_filename = {x[\"id\"]: \"/cis/phd/cxz2081/data/mscoco/captioning/val2014/\" + x[\"file_name\"] for x in caption_data[\"images\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "INFO:tensorflow:Initializing vocabulary from file: data/mscoco/word_counts.txt\n",
      "INFO:tensorflow:Created vocabulary with 11520 words\n",
      "INFO:tensorflow:Running caption generation on 5 files matching.\n"
     ]
    }
   ],
   "source": [
    "# Build the inference graph.\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n",
    "                                           FLAGS.checkpoint_path)\n",
    "g.finalize()\n",
    "\n",
    "# Create the vocabulary.\n",
    "vocab = vocabulary.Vocabulary(FLAGS.vocab_file)\n",
    "\n",
    "filenames = []\n",
    "for file_pattern in FLAGS.input_files:\n",
    "    filenames.extend(tf.gfile.Glob(file_pattern))\n",
    "tf.logging.info(\"Running caption generation on %d files matching.\",\n",
    "              len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: model/train/model.ckpt-829178\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-829178\n",
      "Captions for image COCO_val2014_000000126229.jpg:\n",
      "  0) a tennis player on a court with a racket (p=0.001882)\n",
      "  1) a tennis player on the court with a racket (p=0.000167)\n",
      "  2) a tennis player on a court with a tennis racket (p=0.000117)\n",
      "Captions for image COCO_val2014_000000579325.jpg:\n",
      "  0) a large jetliner sitting on top of an airport tarmac . (p=0.010742)\n",
      "  1) a large jetliner sitting on top of an airport runway . (p=0.007201)\n",
      "  2) a large passenger jet sitting on top of an airport tarmac . (p=0.004929)\n",
      "Captions for image COCO_val2014_000000499989.jpg:\n",
      "  0) a giraffe standing in the middle of a field . (p=0.003387)\n",
      "  1) a giraffe standing in the middle of a forest . (p=0.001570)\n",
      "  2) a giraffe standing in the middle of a lush green field . (p=0.001259)\n",
      "Captions for image COCO_val2014_000000065024.jpg:\n",
      "  0) a panda bear sitting on top of a log . (p=0.000578)\n",
      "  1) a panda bear sitting on top of a tree . (p=0.000538)\n",
      "  2) a panda bear sitting on top of a tree stump . (p=0.000252)\n",
      "Captions for image COCO_val2014_000000575897.jpg:\n",
      "  0) a group of people riding skis down a snow covered slope . (p=0.002538)\n",
      "  1) a group of people standing on top of a snow covered slope . (p=0.002391)\n",
      "  2) a group of people riding skis on top of a snow covered slope . (p=0.001879)\n"
     ]
    }
   ],
   "source": [
    "# generate captions\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "\n",
    "    # Prepare the caption generator. Here we are implicitly using the default\n",
    "    # beam search parameters. See caption_generator.py for a description of the\n",
    "    # available beam search parameters.\n",
    "    generator = caption_generator.CaptionGenerator(model, vocab)\n",
    "\n",
    "    captions_results = []\n",
    "    for filename in filenames:\n",
    "        with tf.gfile.GFile(filename, \"r\") as f:\n",
    "            image = f.read()\n",
    "        captions = generator.beam_search(sess, image)\n",
    "        print(\"Captions for image %s:\" % os.path.basename(filename))\n",
    "        for i, caption in enumerate(captions):\n",
    "            # Ignore begin and end words.\n",
    "            sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            sentence = \" \".join(sentence)\n",
    "            if i == 0:\n",
    "                # save the caption with highest score.\n",
    "                captions_results.append({'image_id': filename_to_id[filename], 'caption':sentence})\n",
    "            print(\"  %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: Saving json file to disk is problemetic in jupyuter notebook. \\nuse python file to save it as json.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # save captions in json format, as a list of dict\n",
    "# with open('results/mscoco_captioning_results.json', 'w') as f:\n",
    "#     json.dump(captions_results,f)\n",
    "\n",
    "'''\n",
    "NOTE: Saving json file to disk is problemetic in jupyuter notebook. \n",
    "use python file to save it as json.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation <a id=\"evaluation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from coco_caption.pycocotools.coco import COCO\n",
    "from coco_caption.pycocoevalcap.eval import COCOEvalCap\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "\n",
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cis/phd/cxz2081/data/mscoco/captioning/annotations/captions_val2014_addtype.json\n",
      "./results/captions_selftest2014_rhn_results.json\n",
      "./results/captions_selftest2014_rhn_evalImgs.json\n",
      "./results/captions_selftest2014_rhn_eval.json\n"
     ]
    }
   ],
   "source": [
    "# set up file names and pathes\n",
    "homeDir = '/cis/phd/cxz2081'\n",
    "dataSetDir = 'data/mscoco/captioning'\n",
    "dataDir='.'\n",
    "annFile='%s/%s/annotations/captions_val2014_addtype.json'%(homeDir,dataSetDir)\n",
    "subtypes=['results', 'evalImgs', 'eval']\n",
    "[resFile, evalImgsFile, evalFile]= \\\n",
    "['%s/results/captions_selftest2014_rhn_%s.json'%(dataDir,subtype) for subtype in subtypes]\n",
    "\n",
    "print(annFile)\n",
    "print(resFile)\n",
    "print(evalImgsFile)\n",
    "print(evalFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:01.035807\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# create coco object and cocoRes object\n",
    "coco = COCO(annFile)\n",
    "cocoRes = coco.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'reflen': 45, 'guess': [48, 43, 38, 33], 'testlen': 48, 'correct': [38, 20, 9, 3]}\n",
      "ratio: 1.06666666664\n",
      "Bleu_1: 0.792\n",
      "Bleu_2: 0.607\n",
      "Bleu_3: 0.443\n",
      "Bleu_4: 0.298\n",
      "computing METEOR score...\n",
      "METEOR: 0.243\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.548\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.194\n"
     ]
    }
   ],
   "source": [
    "# create cocoEval object by taking coco and cocoRes\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "\n",
    "# evaluate on a subset of images by setting\n",
    "# cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "# please remove this line when evaluating the full validation set\n",
    "cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "\n",
    "# evaluate results\n",
    "cocoEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIDEr: 1.194\n",
      "Bleu_4: 0.298\n",
      "Bleu_3: 0.443\n",
      "Bleu_2: 0.607\n",
      "Bleu_1: 0.792\n",
      "ROUGE_L: 0.548\n",
      "METEOR: 0.243\n"
     ]
    }
   ],
   "source": [
    "# print output evaluation scores\n",
    "for metric, score in cocoEval.eval.items():\n",
    "    print('%s: %.3f'%(metric, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # demo how to use evalImgs to retrieve low score result\n",
    "# evals = [eva for eva in cocoEval.evalImgs if eva['CIDEr']<30]\n",
    "# print 'ground truth captions'\n",
    "# imgId = evals[0]['image_id']\n",
    "# annIds = coco.getAnnIds(imgIds=imgId)\n",
    "# anns = coco.loadAnns(annIds)\n",
    "# coco.showAnns(anns)\n",
    "\n",
    "# print '\\n'\n",
    "# print 'generated caption (CIDEr score %0.1f)'%(evals[0]['CIDEr'])\n",
    "# annIds = cocoRes.getAnnIds(imgIds=imgId)\n",
    "# anns = cocoRes.loadAnns(annIds)\n",
    "# coco.showAnns(anns)\n",
    "\n",
    "# img = coco.loadImgs(imgId)[0]\n",
    "# I = io.imread('%s/images/%s/%s'%(dataDir,dataType,img['file_name']))\n",
    "# plt.imshow(I)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # plot score histogram\n",
    "# ciderScores = [eva['CIDEr'] for eva in cocoEval.evalImgs]\n",
    "# plt.hist(ciderScores)\n",
    "# plt.title('Histogram of CIDEr Scores', fontsize=20)\n",
    "# plt.xlabel('CIDEr score', fontsize=20)\n",
    "# plt.ylabel('result counts', fontsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save evaluation results to ./results folder\n",
    "json.dump(cocoEval.evalImgs, open(evalImgsFile, 'w'))\n",
    "json.dump(cocoEval.eval,     open(evalFile, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
